인공지능(Artificial Intelligence, AI)
인공지능이란 인간이 가지고 있는 지적 능력을 컴퓨터에서 구현하는 다양한 기술이나 소프트웨어, 컴퓨터 시스템 등을 가리키며, 알파고의 등장으로 4차 산업혁명의 메인 화두 중 하나로 손꼽히고 있습니다.
이러한 인공지능 기술의 발전은 신속하고 강력한 병렬 처리 기능을 제공하는 그래픽 처리 장치(GPU)의 도입과 폭발적으로 늘어나고 있는 빅데이터를 바탕으로 더욱 가속화되고 있는 추세입니다.
이러한 인공지능(AI) 분야는 딥러닝과 머신러닝보다 훨씬 더 큰 포괄적인 분야라고 할 수 있습니다.

머신러닝(Machine Learning)
머신러닝은 컴퓨터를 인간처럼 학습시킴으로써 컴퓨터가 새로운 규칙을 생성할 수 있지 않을까 하는 시도에서 시작되었습니다.
이처럼 머신러닝이란 컴퓨터가 스스로 학습할 수 있도록 도와주는 알고리즘이나 기술을 개발하는 분야를 가리킵니다.
일반적으로 머신러닝이란 알고리즘을 이용하여 데이터를 분석하고, 이러한 분석 결과를 스스로 학습한 후에 이를 기반으로 어떠한 판단이나 예측을 하는 것을 의미합니다. 따라서 머신러닝에서는 양질의 데이터가 매우 중요한 역할을 하며, 양질의 데이터를 많이 보유할수록 보다 높은 성능을 이끌어낼 수 있게 됩니다.
이러한 머신러닝 분야는 인공지능의 한 분야로 딥러닝을 포함하고 있는 분야입니다.

딥러닝(Deep Learning)
초기의 머신러닝 연구자들은 인간의 뇌가 가지는 생물학적 특성 중 뉴런의 연결 구조를 본떠서 인공신경망(Artificial Neural Network, ANN)이라는 머신러닝 모델을 만들게 됩니다. 그러나 이러한 인공신경망은 기본적인 작업에도 굉장히 많은 양의 연산을 수행해야만 했기에 당시 기술로는 상용화에 무척이나 어려움을 겪게 됩니다.
하지만 토론토 대학의 제프리 힌튼 교수와 같은 일부 교육 기관에서 인공신경망에 대한 연구 개발을 지속적으로 진행해왔고, 병렬 연산에 최적화된 GPU라는 하드웨어가 등장함으로써 그동안 구현할 수 없었던 딥러닝 이론들이 하나 둘씩 실현되게 됩니다.
딥러닝은 이러한 인공신경망에서 더욱 발전된 형태의 인공지능으로, 인공신경망을 여러 개 연결하여 인간의 뇌와 유사한 정보 입출력 계층을 만듦으로써 데이터를 학습하게 됩니다. 이러한 딥러닝의 등장으로 인공지능 분야는 폭발적인 발전을 맞이하게 됩니다.
딥러닝 분야는 머신러닝 모델의 한 종류이므로, 인공지능과 머신러닝에 포함되는 분야입니다.

인공지능 vs 머신러닝 vs 딥러닝
딥러닝 기술의 등장으로 머신러닝의 효율은 급격히 증대되었으며, 인공지능 분야 또한 이전과는 비교할 수 없을 정도로 그 영역을 빠르게 넓혀가고 있습니다. 이러한 인공지능과 머신러닝, 딥러닝은 각각의 개별적인 분야가 아니라 서로가 서로에게 영향을 주는 다음과 같은 포함 관계를 가지고 있는 것입니다.
인공지능 ⊃ 머신러닝 ⊃ 딥러닝

머신러닝(Machine Learning)이란?

머신러닝의 동작 방식
1. 일정량 이상의 샘플 데이터를 입력한다.
2. 입력받은 데이터를 분석하여 일정한 패턴과 규칙을 찾아낸다.
3. 찾아낸 패턴과 규칙을 가지고 의사결정 및 예측등을 수행한다.

수많은 데이터를 학습하여 일정한 패턴을 찾아내고 그것을 활용하는 행위

백터(vector)와 특징량
컴퓨터는 지각능력을 가지고 있지 않으므로, 위치관계를 인식하지 못한다.
이때 활용되는 것이 벡터(vector)이다.
벡터란 공간에서 크기와 방향을 가지는 것을 의미한다.
또한, 특정 벡터들이 모여 있는 것을 특징량이라고 부르며, 머신러닝에서는 바로 이 특징량을 바탕으로 벡터들을 서로 구분하게 됨

특징추출(feature extraction)
머신러닝에서 컴퓨터가 스스로 학습하려면, 즉 컴퓨터가 입력받은 데이터를 분석하여 일정한 패턴이나 규칙을 찾아내려면 사람이 인지하는 데이터를 컴퓨터가 인지할 수 있는 데이터로 변환해 주어야 합니다. 이때 데이터별로 어떤 특징을 가지고 있는지를 찾아내고, 그것을 토대로 데이터를 벡터로 변환하는 작업을 특징추출(feature extraction)이라고 합니다.
feature
일반적으로 사용되는 머신러닝을 위한 학습 기계는 범용적인 목적을 위해 제작된 것이므로, 여러분이 원하는 특징을 자동으로 추출해주는 기능은 가지고 있지 않습니다. 따라서 여러 특징 중에서 어떤 특징을 추출할지를 바로 개발자가 결정해야하며, 이것이 바로 머신러닝 개발의 핵심이라고 볼 수 있습니다.
왜냐하면 적절한 특징을 선택해야만 더욱 효과적인 머신러닝을 수행할 수 있기 때문입니다.
예를 들어, 학습 기계에 장미꽃을 학습시킨다고 하면, 우선 어떤 특징을 사용할 것인지를 결정해야 하며 그것을 벡터로 변환해야 합니다.
이때 특징으로 장미꽃의 색상, 꽃잎 수, 모양 등을 사용할 수 있을 것입니다.

회귀 분석(regression analysis)
앞서 특징량을 바탕으로 구분선을 찾아내는 것을 머신러닝이라고 정의하였는데, 이러한 구분선을 찾아내는 방법 중 가장 널리 사용되는 방식이 바로 회귀 분석(regression analysis)입니다.
통계학에서 주로 사용되는 회귀 분석(regression analysis)이란 여러 자료들 간의 관계성을 수학적으로 추정하고 분석하는 데이터 분석 방법 중 하나입니다. 이러한 회귀 분석은 주로 시간에 따라 변화하는 데이터나 가설, 인과 관계 등의 통계적 예측에 사용됩니다.
회귀 분석에서 종속변수란 우리가 알고 싶어 하는 결괏값을 가리키며, 독립변수란 이러한 결괏값에 영향을 주는 입력값을 가리킵니다.
그리고 하나의 종속변수와 하나의 독립변수 사이의 관계를 분석할 경우를 단순 회귀 분석(simple regression analysis)이라고 구분하여 부릅니다.
regression
단순 회귀 분석에서 하나의 방정식은 독립변수와 종속변수의 상관관계를 보여주는 분포구성을 통해 중심을 지나가는 하나의 선으로 표시할 수 있으며, 바로 이것을 이용하여 머신러닝에서는 특징량에 따른 구분선을 찾아낼 수 있게 되는 것입니다.

머신러닝 – 지도 학습

머신러닝의 분류
머신러닝은 학습하려는 문제의 유형에 따라 크게 다음과 같은 세 가지로 분류할 수 있습니다.
1. 지도 학습(Supervised Learning)
2. 비지도 학습(Unsupervised Learning)
3. 강화 학습(Reinforcement Learning)

지도 학습(Supervised Learning)
지도 학습(Supervised Learning)이란 간단히 말해 선생님이 문제를 내고 그 다음 바로 정답까지 같이 알려주는 방식의 학습 방법입니다.
즉, 여러 문제와 답을 같이 학습함으로써 미지의 문제에 대한 올바른 답을 예측하고자 하는 방법입니다.
따라서 지도 학습을 위한 데이터에는 문제와 함께 그 정답까지 함께 알고 있는 데이터가 선택됩니다.
예를 들어, “장미꽃이 찍혀 있는 이미지 데이터”에 레이블로 “해당 장미꽃의 품종을 나타내는 텍스트“를 함께 입력하여 학습기를 지도 학습시키면, 다른 장미꽃이 찍힌 새로운 이미지를 받았을 때 해당 장미꽃의 품종이 무엇인지를 예측할 수 있게 되는 것입니다.
학습기(learner)에 데이터와 함께 입력하는 정답을 레이블(label)이라고 부릅니다.

지도 학습 모델
머신러닝에서 지도 학습을 위한 모델은 크게 분류(classification) 모델과 예측(prediction) 모델로 구분됩니다.
분류 모델은 사용하는 알고리즘에 따라 또다시 KNN(K Nearest Neighbor), 서포트 벡터 머신(Support Vector Machine, SVM), 의사결정 트리(decision trees) 등의 모델로 구분되며, 예측 모델로는 회귀(regression) 모델이 대표적으로 사용되고 있습니다.
분류 모델과 예측 모델 모두 지도 학습 모델이므로, 데이터와 레이블을 함께 학습시킨다는 공통점을 가집니다.
하지만 분류 모델은 학습 데이터의 레이블 중 하나가 결괏값이 되고, 예측 모델은 학습 데이터에서 도출된 함수식에서 계산된 임의의 값이 결괏값이 되는 점이 서로 다릅니다.

분류(classification) 모델
분류 모델은 레이블이 달린 학습 데이터로 학습한 후에 새로 입력된 데이터가 학습했던 어느 그룹에 속하는 지를 찾아내는 방법입니다.
따라서 분류 모델의 결괏값은 언제나 학습했던 데이터의 레이블 중 하나가 됩니다.
즉, 다음과 같은 이미지를 통해 학습한 결과 새로운 이미지에 해당하는 숫자가 0인지 1인지를 파악하는 것입니다.
dataset
예를 들어, ‘가’, ‘나’, ‘다’라는 레이블이 달린 데이터를 분류 모델로 지도 학습한 후, 새로운 데이터를 분석한 결과는 반드시 ‘가’, ‘나’, ‘다’ 중의 하나가 되는 것입니다.
이러한 유형의 문제는 일상에서 흔히 접할 수 있는 문제이며, 따라서 이에 관한 연구가 많이 진행되어 있습니다. 또한 기업에서도 많은 관심을 가지고 있는 문제 중 하나입니다.

예측 모델(predictive model)
예측 모델도 분류 모델과 마찬가지로 지도 학습 모델이므로 레이블이 달린 학습 데이터로 학습하게 됩니다.
하지만 예측 모델은 분류 모델과는 달리 레이블이 달린 학습 데이터를 가지고 특징(feature)과 레이블(label) 사이의 상관관계를 함수식으로 표현하게 됩니다.
따라서 ‘가’, ‘나’, ‘다’라는 레이블이 달린 데이터를 예측 모델로 지도 학습하였다고 하더라도 분류 모델처럼 결괏값이 반드시 ‘가’, ‘나’, ‘다’ 중 하나가 되는 것이 아니라 해당 범위 내의 어떠한 값도 나올 수 있는 것입니다. 이처럼 어떠한 값이 결과로 나올지 예상할 수 없으므로, 이를 예측 모델이라고 부릅니다.
이러한 예측 모델은 주가나 환율 분석 등과 같이 연속적인 범위 내의 값에서 그 결괏값을 예측하는 문제에 일반적으로 많이 활용됩니다.

머신러닝 – 비지도 학습

비지도 학습(Unsupervised Learning)
선생님이 문제와 함께 정답(레이블)까지 알려주는 지도 학습과는 달리 비지도 학습(Unsupervised Learning)은 문제는 알려주되 정답까지는 알려주지 않는 학습 방식입니다. 즉, 여러 문제를 학습함으로써 해당 데이터의 패턴, 특성 및 구조를 스스로 파악하여, 이를 통해 새로운 데이터에서 일정한 규칙성을 찾는 방법입니다.
비지도 학습은 구체적인 결과에 대한 사전 지식은 없지만 해당 결과 데이터를 통해 유의미한 지식을 얻고자 할 때 사용되며, 사람도 제대로 알 수 없는 본질적인 문제나 데이터에 숨겨진 특징이나 구조 등을 연구할 때 많이 활용됩니다.
머신러닝에서 비지도 학습을 위한 모델로는 군집화(clustering)가 대표적입니다.

군집화(clustering)
비지도 학습에 사용되는 데이터에는 레이블(label)이 명시되어 있지 않기 때문에 지도 학습과는 또 다른 방식으로 학습을 수행해야 합니다.
이때 가장 많이 사용되는 방법이 바로 입력된 데이터가 어떤 형태로 서로 그룹을 형성하는지를 파악하는 것입니다.
비지도 학습에서 가장 대표적으로 사용되는 이 모델은 군집화(clustering) 또는 클러스터링이라고 불립니다.
군집화는 레이블이 없는 학습 데이터들의 특징(feature)을 분석하여 서로 동일하거나 유사한 특징을 가진 데이터끼리 그룹화 함으로써 레이블이 없는 학습 데이터를 군집(cluster, 그룹)으로 분류합니다. 그리고 새로운 데이터가 입력되면 지도 학습의 분류 모델처럼 학습한 군집을 가지고 해당 데이터가 어느 군집에 속하는지를 분석하는 것입니다.
clustering
군집(cluster)의 타당성 평가
비지도 학습에 사용되는 데이터에는 레이블(label)이 없으므로, 지도 학습처럼 단순정확도(accuracy)를 지표로 그 정확도를 평가할 수는 없습니다.
즉, 다음 그림과 같이 레이블이 없는 데이터 집합 내에서 최적의 군집 모양과 개수를 파악하기란 굉장히 어렵습니다.
eval
군집을 만든 결과가 얼마만큼 타당한지는 군집간의 거리, 군집의 지름, 군집의 분산도 등을 종합적으로 고려하여 평가할 수 있습니다.
따라서 일반적으로 군집 간 분산(inter-cluster variance)이 최대가 되고 군집 내 분산(inner-cluster variance)이 최소가 될 때 최적의 군집 모양과 개수라고 판단하고 있습니다.

군집화의 분류
군집화의 주목적은 레이블이 없는 데이터 집합의 요약된 정보를 추출하여, 이를 가지고 전체 데이터 집합이 가지고 있는 특징을 찾는 것입니다.
이러한 군집화는 사용하는 알고리즘에 따라 크게 두 가지 기법으로 나눌 수 있습니다.
1. 분할 기법(partitioning methods)의 군집화
2. 계층적 기법(hierarchical methods)의 군집화
분할 기법의 군집화는 각 그룹은 적어도 하나의 데이터를 가지고 있어야 하며 각 데이터는 정확히 하나의 그룹에 속해야 한다는 규칙을 가지고 데이터 집합을 작은 그룹으로 분할하는 방식입니다. 이러한 분할 기법의 군집화에는 k-means, k-medoids, DBSCAN 등의 기법 등이 있습니다.
계층적 기법의 군집화는 데이터 집합을 계층적으로 분해하는 방식으로 그 방식에 따라 또다시 집괴적(agglomerative) 군집화와 분할적(divisive) 군집화로 나눠집니다.

군집화의 활용
군집화는 매우 다양한 분야에서 사용되고 있는 머신러닝 방법으로, 의학 분야에서는 특정 질병에 대한 공간 군집 분석을 통해 질병의 분포 면적과 확산 경로 등을 파악하는 역학 조사 등에서 활용되고 있으며, 홍보 분야에서는 고객을 세분화할 때 군집화를 활용하고 있습니다.
또한, 통계 분야에서도 분석하고자 하는 데이터에 다양한 군집화 알고리즘과 방법론을 사용하여 데이터 분석에 활용해 나가고 있는 추세입니다.

머신러닝 – 강화 학습

강화 학습(Reinforcement Learning)
지도 학습과 비지도 학습이 학습 데이터가 주어진 상태에서 환경에 변화가 없는 정적인 환경에서 학습을 진행했다면, 강화 학습은 어떤 환경 안에서 정의된 주체(agent)가 현재의 상태(state)를 관찰하여 선택할 수 있는 행동(action)들 중에서 가장 최대의 보상(reward)을 가져다주는지 행동이 무엇인지를 학습하는 것입니다.
강화 학습은 주체(agent)가 환경으로부터 보상을 받음으로써 학습하기 때문에 지도 학습과 유사해 보이지만, 사람으로부터 학습을 받는 것이 아니라 변화되는 환경으로부터 보상을 받아 학습한다는 점에서 차이를 보입니다.
이러한 강화 학습은 사람이 지식을 습득하는 방식 중 하나인 시행착오를 겪으며 학습하는 것과 매우 흡사하여 인공지능을 가장 잘 대표하는 모델로 알려져 있습니다.
강화 학습의 동작 순서
강화 학습은 일반적으로 다음과 같은 순서대로 학습을 진행하게 됩니다.
1. 정의된 주체(agent)가 주어진 환경(environment)의 현재 상태(state)를 관찰(observation)하여, 이를 기반으로 행동(action)을 취합니다.
2. 이때 환경의 상태가 변화하면서 정의된 주체는 보상(reward)을 받게 됩니다.
3. 이 보상을 기반으로 정의된 주체는 더 많은 보상을 얻을 수 있는 방향(best action)으로 행동을 학습하게 됩니다.
reinfroce
강화 학습에서의 ‘관찰–행동–보상’에 이르는 일련의 과정을 경험(experience)이라고 부를 수 있습니다.
이용(exploitation)과 탐험(exploration) 사이의 균형
경험을 통해 학습하는 강화 학습에서 최단 시간에 주어진 환경의 모든 상태를 관찰하고, 이를 기반으로 보상을 최대화할 수 있는 행동을 수행하기 위해서는 이용(exploitation)과 탐험(exploration) 사이의 균형을 적절히 맞춰야 합니다.
이용(exploitation)이란 현재까지의 경험 중 현 상태에서 가장 최대의 보상을 얻을 수 있는 행동을 수행하는 것을 의미하고, 이러한 다양한 경험을 쌓기 위해서는 새로운 시도가 필요한데 이러한 새로운 시도를 탐험(exploration)이라고 합니다.
탐험을 통해 얻게 되는 경험이 언제나 최상의 결과일 수는 없기에 이 부분에서 낭비가 발생하게 됩니다. 즉, 풍부한 경험이 있어야만 더 좋은 선택을 할 수 있게 되지만, 경험을 풍부하게 만들기 위해서는 새로운 시도를 해야 하고 이러한 새로운 시도는 언제나 위험 부담을 가지게 됩니다.
rein
예를 들어, 빵집에 가서 지금까지 자신이 먹어본 빵 중 가장 맛있는 빵을 고르는 것이 이용(exploitation)이 되며, 한 번도 먹어보지 못한 다른 빵을 고르는 것이 탐험(exploration)이 됩니다. 만약 새로 고른 빵이 가장 맛있다고 느껴지면 다음 번 선택에서 이용될 수 있으나, 만약 맛이 없었다면 한 번의 기회를 낭비하게 된 것입니다.
따라서 이용과 탐험 사이의 적절한 균형을 맞추는 것이 강화 학습의 핵심이 되는 것입니다.
마르코프 결정 프로세스(Markov Decision Process, MDP)
강화 학습에서 보상을 최대화할 수 있는 방향으로 행동을 취할 수 있도록 이용과 탐험 사이의 적절한 균형을 맞추는데 사용되는 의사결정 프로세스가 바로 마르코프 결정 프로세스(Markov Decision Process, MDP)입니다.
MDP에서 행위의 주체(agent)는 어떤 상태(state)를 만나면 행동(action)을 취하게 되며, 각 상태에 맞게 취할 수 있는 행동을 연결해 주는 함수를 정책(policy)이라고 합니다. 따라서 MDP는 행동을 중심으로 가치 평가가 이루어지며, MDP의 가장 큰 목적은 가장 좋은 의사결정 정책(policy) 즉 행동에 따른 가치(value)의 합이 가장 큰 의사결정 정책을 찾아내는 것입니다.
mdp
이러한 MDP는 여러 방식을 통해 풀 수 있으며, 일반적으로 동적 계획법(dynamic programming)인 가치 반복법(Value Iteration, VI)이나 정책 반복법(Policy Iteration, PI), 선형 계획법(linear programming)인 Q러닝(Q-Learning) 등을 사용하여 그 해를 구하게 됩니다.
강화 학습의 활용
강화 학습은 프로세스 제어, 네트워크 관리, 로봇공학 등 현재 다양한 분야에서 활용되고 있습니다.
우리에게 익숙한 인공지능인 알파고도 바둑의 기본 규칙과 자체 경기를 통해 습득한 3,000만 개의 기보를 학습한 후 스스로 대국하며 훈련하는 강화 학습 알고리즘을 사용하여 개발되었습니다.
또한, 자율 주행 자동차와 드론 분야 등에서도 강화 학습을 활용한 다양한 연구 및 시도가 활발히 진행되고 있습니다.
머신러닝 알고리즘
머신러닝 알고리즘
머신러닝은 학습하려는 문제의 유형에 따라 크게 지도 학습, 비지도 학습, 그리고 강화 학습으로 나눌 수 있습니다.
그리고 각 학습 방법들은 상황에 맞는 다양한 알고리즘을 사용하여 구현할 수 있습니다.
다음은 머신러닝 학습에서 사용되는 대표적인 알고리즘입니다.
1. 서포트 벡터 머신(Support Vector Machine, SVM)
2. K-means 군집화(K-means clustering)
3. 의사 결정 트리(Decision tree)

서포트 벡터 머신(Support Vector Machine, SVM)
서포트 벡터 머신(SVM)은 머신러닝의 지도 학습 중 분류(classification) 모델에서 최근까지도 가장 많이 사용되는 알고리즘입니다.
SVM은 지금까지 수많은 연구가 진행되어 왔기에 굉장히 높은 인식률을 보여주며, 주로 다루려는 데이터가 2개의 그룹으로 분류될 때 많이 사용됩니다.
SVM은 학습 데이터가 벡터 공간에 위치하고 있다고 생각하며 학습 데이터의 특징(feature) 수를 조절함으로써 2개의 그룹을 분류하는 경계선을 찾고, 이를 기반으로 패턴을 인식하는 방법입니다.
svm
두 그룹을 분류하는 경계선은 최대한 두 그룹에서 멀리 떨어져 있는 경계선을 구하게 되며, 이는 두 그룹과의 거리(margin)를 최대로 만드는 것이 나중에 입력된 데이터를 분류할 때 더 높은 정확도를 얻을 수 있기 때문입니다.
이러한 SVM은 필기체 인식이나 이미지 분류 등에서 학습하는 데이터의 양을 줄일 수 있도록 도와줍니다.

K-means 군집화(K-means clustering)
K-means 군집화는 비지도 학습의 군집화 중에서도 분할 기반(partition-based)의 군집화에 속하는 방법이며, 가장 간단한 비지도 학습 알고리즘 중 하나입니다.
kmeans
K-means 군집화의 학습 순서는 다음과 같습니다.
1. 총 n개의 데이터를 학습할 경우 n보다 작거나 같은 k를 결정한 후, 임의의 중심점을 k개 설정함.
2. 모든 학습 데이터는 k개의 중심점까지의 거리를 각각 계산한 후에 가장 가까운 중심점을 자신이 속한 군집(cluster)의 중심점이라고 저장함.
3. 각 군집에 속한 데이터에 저장된 중심점 좌표값들의 평균을 구한 뒤 이를 바탕으로 해당 군집의 새로운 중심점을 설정함.
4. 새롭게 설정된 중심점을 가지고 2단계와 3단계를 다시 반복함.
5. 모든 학습 데이터가 자신이 속한 군집을 변경하지 않는 경우 학습을 완료함.
K-means 군집화는 알고리즘의 개념이 매우 직관적이며, 학습을 위해 수행해야 할 데이터의 계산의 양이 매우 적다는 장점을 가집니다.
하지만 모양이 구형(spherical)이 아닌 군집에 대해서는 정확도가 떨어지며, 동떨어져 있는 데이터 즉 이상값(outlier)에 매우 민감하다는 단점도 가집니다. 또한, 맨 처음에 결정한 군집의 개수인 k에 따라 결과값이 완전히 달라지는 경우도 발생할 수 있습니다.
이러한 K-means 군집화는 시장 분석, 이미지 작업, 지질 통계학, 천문학 등 광범위한 분야에서 활용되고 있으며, 특히 다른 알고리즘을 수행하기 전에 학습 데이터를 전처리(pre-processing)하는 용도로도 많이 사용되고 있습니다.

의사 결정 트리(Decision tree)
귀납적 추론을 기반으로 하는 의사 결정 트리(Decision tree)는 데이터를 분석하여 이들 사이에 존재하는 패턴을 시각적이고도 명시적인 방법으로 보여주는 지도 학습 알고리즘 중 하나입니다.
dt
의사 결정 트리는 지도 학습의 분류 모델이나 회귀 모델 둘 다에 적용할 수 있습니다.
의사 결정 트리의 기본 개념은 질문을 던져 답을 얻음으로써 그 대상을 좁혀나가는 일종의 ‘스무고개’ 놀이와 비슷한 개념입니다.
의사 결정 트리의 분석 결과는 ‘조건 A이고 조건 B이면 결과는 C’라는 형태로 표현되므로 쉽게 이해할 수 있으며, 따라서 다른 알고리즘에 비해 쉽게 활용할 수 있는 장점을 가지고 있습니다.
의사 결정 트리는 분석 순서는 다음과 같습니다.
1. 목표 속성(target attribute)과 이와 관계가 있는 후보 속성(candidate attribute)들을 선택함.
2. 데이터를 분석하는 목적과 자료 구조에 따라 적절한 분리 기준과 정지 규칙을 정하여 트리 구조를 작성함.
3. 완성된 트리 구조에서 정확도를 떨어뜨리는 속성은 제거함.(가지치기, pruning)
정지 규칙이란 더 이상 분리가 일어나지 않고 현재 노드가 잎 노드(leaf node)가 되도록 하는 여러 규칙들을 의미합니다.
이러한 의사 결정 트리는 환자의 과거 진료 기록을 토대로 증상을 유추하거나 대출을 위한 신용평가, 고객의 소비 행동 예측 등 다양한 분야에서 활용되고 있습니다.

딥러닝이란?
딥러닝(Deep Learning)이란?
딥러닝(Deep Learning)이란 여러 층을 가진 인공신경망(Artificial Neural Network, ANN)을 사용하여 머신러닝 학습을 수행하는 것으로 심층학습이라고도 부릅니다. 따라서 딥러닝은 머신러닝과 전혀 다른 개념이 아니라 머신러닝의 한 종류라고 할 수 있습니다.
기존의 머신러닝에서는 학습하려는 데이터의 여러 특징 중에서 어떤 특징을 추출할지를 사람이 직접 분석하고 판단해야만 했습니다.
하지만 딥러닝에서는 기계가 자동으로 학습하려는 데이터에서 특징을 추출하여 학습하게 됩니다.
이처럼 딥러닝과 머신러닝의 가장 큰 차이점은 바로 기계의 자가 학습 여부로 볼 수 있습니다.
따라서 딥러닝이란 기계가 자동으로 대규모 데이터에서 중요한 패턴 및 규칙을 학습하고, 이를 토대로 의사결정이나 예측 등을 수행하는 기술로 정의내릴 수 있습니다.

인공신경망(Artificial Neural Network, ANN)
딥러닝에서 가장 기본이 되는 개념은 바로 신경망(Neural Network)입니다.
신경망이란 인간의 뇌가 가지는 생물학적 특성 중 뉴런의 연결 구조를 가리키며, 이러한 신경망을 본떠 만든 네트워크 구조를 인공신경망(Artificial Neural Network, ANN)이라고 부릅니다.
인간의 뇌에는 약 1,000억 개의 수많은 뉴런 즉 신경세포가 존재하며, 하나의 뉴런은 다른 뉴런에게서 신호를 받고 또 다른 뉴런에게 신호를 전달하는 단순한 역할만을 수행합니다. 하지만 인간의 뇌는 이러한 수많은 뉴런이 모여 만든 신호의 흐름을 기반으로 다양한 사고를 할 수 있게 되며, 이것을 컴퓨터로 구현하도록 노력한 것이 바로 인공신경망입니다.
인공지능 분야에서 신경망이란 보통 인공신경망을 지칭하며, 따라서 인공신경망을 따로 구분하지 않고 신경망이라고 부르기도 합니다.
인공신경망은 여러 뉴런이 서로 연결되어 있는 구조의 네트워크이며, 입력층(input layer)를 통해 학습하고자 하는 데이터를 입력받게 됩니다.
이렇게 입력된 데이터들은 여러 단계의 은닉층(hidden layer)을 지나면서 처리가 이루어져 출력층(output layer)을 통해 최종 결과가 출력되게 됩니다.
이러한 신경망을 3개 이상 중첩한 구조를 깊은 신경망(Deep Neural Network, DNN)이라고 부르며, 이를 활용한 머신러닝 학습을 특별히 딥러닝이라고 부르는 것입니다.

퍼셉트론(perceptron)
퍼셉트론(perceptron)이란 1957년 미국의 심리학자 프랑크 로젠블라트(Frank Rosenblatt)에 의해 고안된 인공신경망 이론을 설명한 최초의 알고리즘이라고 할 수 있습니다. 로젠블라트는 가장 간단한 퍼셉트론으로 입력층과 출력층만으로 구성된 단층 퍼셉트론(single layer perceptron)의 개념을 제안했습니다.
단층 퍼셉트론(single layer perceptron)이 동작하는 방식은 다음과 같습니다.
1. 각 노드의 입력치와 가중치를 서로 곱하여 모두 합한다.
2. 이렇게 합한 값을 활성화 함수가 가지고 있는 임계치(선택의 기준이 되는 값)와 서로 비교한다.
3. 만약 그 값이 임계치보다 크면 뉴런은 활성화되고, 만약 임계치보다 작으면 뉴런은 비활성화 된다.
이러한 단층 퍼셉트론에서 가중치와 임계치를 적절히 변경하면, 상황에 맞는 적절한 의사결정을 내릴 수 있게 됩니다.
또한, 단층 퍼셉트론을 여러 개 조합하면 더욱 복잡한 문제도 판단할 수 있게 되며, 이를 다층 퍼셉트론(MultiLayer Perceptron, MLP)이라고 부릅니다.
다층 퍼셉트론은 단층 퍼셉트론을 사용해서는 풀지 못하는 비선형 문제까지도 풀 수 있습니다.
일반적으로 인공신경망이란 이와 같은 다층 퍼셉트론의 조합이라 할 수 있습니다.

딥러닝의 역사
딥러닝의 겨울
1957년 프랑크 로젠블라트(Frank Rosenblatt)가 퍼셉트론 이론을 발표한 이래 인공신경망 이론은 효과적인 학습 모델을 찾지 못한 채 여러 가지 문제에 직면하게 됩니다.
역전파(backpropagation)법에서 인공신경망의 레이어(layer)가 늘어날수록 오래 전 데이터에서 기울기가 사라지는 문제(vanishing gradient problem)와 학습 데이터를 과하게 학습하여 학습 데이터에 대해서는 오차가 감소하지만 실제 데이터에 대해서는 오히려 오차가 증가하는 과적합(overfitting) 문제, 마지막으로 문제의 규모가 커질 때마다 나타나는 높은 시간 복잡도와 컴퓨터 성능의 한계 등으로 인해 인공신경망 이론은 큰 진전을 보지 못하고 정체 상태를 맞이하게 됩니다.

딥러닝의 부활
2006년 토론토 대학의 제프리 힌튼(Geoffrey Hinton) 교수는 심층 신뢰 신경망(Deep Belief Network, DBN)이라는 딥러닝에 매우 효과적인 알고리즘에 관한 논문을 발표합니다. 제프리 힌튼 교수는 이 논문을 실제 적용하여 2012년 세계 최대 이미지 인식 경연대회인 ILSVRC에서 나머지 팀들이 26% 대의 이미지 인식 오류율로 각축을 벌일 때 홀로 15% 대의 오류율을 기록함으로써 1위를 차지하게 됩니다.
인공지능 분야의 전문가들 대부분은 제프리 힌튼 교수의 이 논문이 딥러닝의 부활을 알리는 계기가 되었다고 말하고 있습니다.
또한, 기울기가 사라지는 문제(vanishing gradient problem)를 해결하기 위해 기존에 사용하던 시그모이드(sigmoid) 함수 대신에 ReLU(Rectified Linear Unit)라는 함수가 새롭게 고안되었으며, 드롭아웃 계층(dropout layer)을 사용하여 학습 중일 때 랜덤하게 뉴런을 비활성화 함으로써 학습이 학습 데이터에 치우치는 과적합(overfitting) 문제를 해결하였습니다.
이러한 혁신적인 알고리즘의 개발과 더불어 컴퓨터 하드웨어의 급속한 발달, GPU를 활용한 병렬처리 기술의 개발 등으로 딥러닝은 획기적으로 그 성능이 향상되어 새로운 도약의 시대를 맞이하게 됩니다.

딥러닝의 도약과 그 원동력
딥러닝은 세계경제포럼 선정 2017년도 10대 미래유망기술, IEEE 컴퓨터 협회 선정 2018년도 10대 기술 트렌드 등 미래를 선도할 혁신 기술의 하나로 각광받고 있습니다.
딥러닝이 이렇게 빠르게 발전할 수 있었던 원동력은 다음과 같습니다.
1. GUP 기반의 병렬처리를 포함한 컴퓨팅 파워(computing power)의 발달
2. 인터넷을 통해 축적된 엄청난 양의 빅데이터(big data)
3. 딥러닝을 위한 획기적인 알고리즘의 고안
이 중에서도 빠른 시간 안에 더욱 빠르게 발전할 수 있는 가능성을 가지고 있는 분야는 바로 알고리즘 분야입니다.

딥러닝 알고리즘
딥러닝에 사용되는 인공신경망 알고리즘에는 심층 신경망(DNN), 컨볼루션 신경망(CNN), 순환 신경망(RNN), 제한 볼츠만 머신(RBM), 심층 신뢰 신경망(DBN), 심층 Q-네트워크(Deep Q-Networks) 등 다양한 형태의 수많은 알고리즘이 각각의 장단점을 가지고 활용되고 있습니다.
특정 형태의 문제를 잘 해결하는 알고리즘이 다른 형태의 문제는 잘 풀지 못 할 수도 있으며, 이것이 이렇게 다양한 알고리즘이 개발되어 사용되고 있는 이유 중 하나입니다. 상황에 알맞게 제대로 고안된 딥러닝 알고리즘은 인간의 사고와 분석의 한계를 넘어 엄청난 양의 데이터로부터 비즈니스적 가치(value)를 창출할 수 있도록 도와줍니다.

인공신경망 핵심 알고리즘
딥러닝에 사용되는 인공신경망 알고리즘은 매우 다양하지만 몇 가지의 대표적인 알고리즘에서 파생된 것들이 대부분입니다.
다음은 대표적인 인공신경망 알고리즘 중에서도 가장 기본적이고 이해하기 쉬운 알고리즘입니다.
1. 컨볼루션 신경망(Convolutional Neural Network, CNN)
2. 심층 신뢰 신경망(Deep Belief Network, DBN)
컨볼루션 신경망(Convolutional Neural Network, CNN)
비전(vision) 분야에서 다층 퍼셉트론(MultiLayer Perceptron, MLP)을 이용하면 이론적으로 학습은 가능하지만 영상의 크기가 커질수록 학습해야 하는 데이터의 크기나 학습 시간이 매우 커지게 되며, 이미지의 위치, 각도, 크기 변화에도 취약해지는 단점을 가지게 됩니다.
이러한 문제점을 해결하기 위해 고안된 지도 학습 알고리즘인 컨볼루션 신경망(CNN)은 인간의 시신경 구조를 모방하여 만들어졌으며, 특징(feature)을 추출하는 일종의 필터인 컨볼루션 커널(convolution kernel)을 도입하여 입력된 이미지를 분류하기 위한 변별적 학습을 수행합니다.
또한, 최대 풀링(max pooling)과 평균 풀링(average pooling)과 같은 서브 샘플링(sub-sampling)을 통해 이웃하고 있는 데이터 간의 대비율(contrast)을 높이고 처리해야 할 데이터의 양을 줄여줍니다.
컨볼루션 커널을 이용한 필터링 단계와 풀링을 이용한 서브 샘플링 단계를 여러 번 반복함으로써 CNN은 이미지의 위치나 각도 변화 등에도 변함없이 강건함(topology invariance)을 유지할 수 있게 됩니다.
CNN은 이미지의 추상적인 특징을 여러 관점에서 추출함으로써 위치에 무관한 특징을 추출하고, 학습해야 할 전체 매개변수의 수를 감소시켜 빠른 학습 속도와 우수한 일반화 능력을 가질 수 있도록 도와줍니다.

심층 신뢰 신경망(Deep Belief Network, DBN)
심층 신뢰 신경망(DBN)은 입력층과 하나의 은닉층으로 구성되어 있는 제한 볼츠만 머신(Restricted Boltzmann Machine, RBM)을 빌딩블럭(building block)과 같이 여러 층으로 쌓아 올린 형태의 신경망으로, 입력 데이터와 같은 출력을 재생성하는 모델입니다.
여러 층으로 이루어진 인공신경망 학습에서는 신경망의 레이어(layer)가 늘어날수록 오래 전 데이터에서 기울기가 사라지는 문제(vanishing gradient problem)가 발생합니다. 이 문제를 해결하기 위해 DBN에서는 입력으로부터 가까운 층부터 차례대로 RBM을 이용한 일종의 비지도 학습인 사전 학습을 수행하며, 이것을 층별 선훈련(layer-wise pre-training)이라고 합니다.
DBN에서 1단계 RBM의 사전 학습이 완료되면 그 결괏값이 2단계 RBM의 입력값으로 사용되며, 이때 1단계에서 사용된 가중치는 고정됩니다. 이와 같은 방법으로 마지막 은닉층까지 순서대로 반복되며, 이와 같은 층별 선훈련의 목적은 각 은닉층에 존재하는 가중치를 가능한 한 목푯값에 가깝도록 만드는 것입니다.
DBN은 비지도 학습인 RBM을 기반으로 여러 번의 사전 학습을 통해 가중치를 어느 정도 보정하고, 역전파 및 피드포워드 알고리즘을 통해 최종 가중치를 계산하게 됩니다. 이러한 특성은 학습 데이터의 양이 적을 때 굉장히 유용하게 사용됩니다.
이러한 DBN은 입력 데이터와 같은 출력 데이터를 재생성함으로 오토인코더나 분류기 등에 활용될 수 있으며, 이미지에서 사람의 얼굴 방향 인식 문제나 문서의 코드화 작업 등에 사용되고 있습니다.

딥러닝 프레임워크
딥러닝에 사용되는 인공신경망 알고리즘에는 DNN, CNN, RNN, RBM, DBN 등 다양한 형태의 수많은 알고리즘이 개발되어 활용되고 있으며, 하나의 문제를 해결하기 위해 두 개 이상의 알고리즘을 혼합하여 사용하는 경우도 많아졌습니다. 이렇게 이미 검증된 알고리즘을 사용할 때마다 계속해서 새롭게 구현해야 한다는 것은 매우 비효율적 방식입니다.
딥러닝 프레임워크(framework)는 이렇게 이미 검증된 수많은 라이브러리와 사전 학습까지 완료된 다양한 딥러닝 알고리즘을 제공함으로써, 개발자가 이를 빠르고 손쉽게 사용할 수 있도록 해줍니다. 이를 통해 중복적인 기능을 구현해야 하는 소모적인 작업으로부터 개발자를 해방시켜, 문제 해결을 위한 핵심 알고리즘 개발에만 집중할 수 있도록 도와줍니다.
프레임워크(framework)란 응용 프로그램을 개발하기 위한 여러 라이브러리나 모듈 등을 효율적으로 사용할 수 있도록 하나로 묶어 놓은 일종의 패키지라고 할 수 있습니다.
딥러닝 개발에 사용되는 프레임워크는 특정 딥러닝 분야에 특화되어 있거나 기능상의 차이가 있을 수 있으므로, 자신이 개발하고자 하는 분야와 목적에 따라 알맞은 프레임워크를 선택해야 합니다.
현재 가장 인기 있는 대표적인 딥러닝 프레임워크는 다음과 같습니다.
1. 시아노(Theano)
2. 텐서플로우(Tensorflow)
3. 케라스(Keras)
4. 토치(Torch)
5. DL4J(DeepLearning4J)

시아노(Theano)
최초의 딥러닝 프레임워크 중 하나인 시아노(Theano)는 파이썬을 기반으로 개발되었으며, 데이터를 탐색하거나 수치 계산에 매우 유용합니다.
하지만 확장성이 뛰어나지는 않으며 다중 GPU에 대한 지원도 부족합니다.
그러나 아직까지도 범용적인 딥러닝 모델을 구축할 때 많이 사용되고 있습니다.

텐서플로우(Tensorflow)
현재 가장 인기 있는 딥러닝 프레임워크 중 하나인 텐서플로우(Tensorflow)는 시아노(Theano)를 대신하기 위해 구글의 구글 브레인 팀에서 개발한 딥러닝 프레임워크입니다.
텐서플로우는 C/C++ 엔진에 파이썬 API로 제작되어 빠른 실행이 가능하며, 딥러닝 알고리즘뿐만 아니라 강화 학습을 위한 다양한 알고리즘도 같이 지원하고 있습니다. 또한, 텐서보드(TensorBoard)라는 모델 가상화 도구를 제공하여 모델을 손쉽게 시각화할 수 있습니다.
하지만 다른 프레임워크에 비해 속도가 느린 편이며, 스칼라(Scala) 언어는 지원하지 않고 있습니다.
2015년 구글이 텐서플로우를 오픈 소스로 공개한 이후 매우 활발하게 연구가 진행되어 2018년 현재 r1.8버전까지 공개되어 있으며, 지원하는 언어도 파이썬, C/C++뿐만 아니라 자바, Go 언어까지 추가되었습니다.

케라스(Keras)
시아노(Theano)나 텐서플로우(Tensorflow)를 사용하여 직접 딥러닝 모델을 만드는 것은 딥러닝 전문가가 아니면 매우 어려울 수 있습니다.
이를 해결하기 위해서 효율적인 인공신경망을 단순화된 인터페이스로 구축할 수 있도록 개발된 딥러닝 프레임워크가 바로 케라스(Keras)입니다.
케라스(Keras)는 시아노(Theano)와 텐서플로우(Tensorflow)를 백엔드(back-end)로 사용하며, 토치(Torch)와 같이 직관적인 API를 제공합니다.
또한, 파이썬으로 제작되어 매우 가볍고 배우기도 쉬우며, 빠른 업데이트로 다양한 계층에서 빠른 속도로 발전하고 있는 차세대 딥러닝 프레임워크라고 할 수 있습니다.

토치(Torch)
토치(Torch)는 루아(Lua)라는 스크립트 언어를 기반으로 제작된 딥러닝 프레임워크로 페이스 북, 구글 등과 같은 대기업에서도 토치를 기반으로 하는 자체 버전을 별도로 개발하여 사용하고 있을 정도로 효율적인 프레임워크입니다.
토치(Torch)는 딥러닝 모델을 만드는 과정을 최대한 유연하고 간단하게 만드는 것을 목표로 개발되었으며, 강화 학습에 필요한 사전 학습된 다양한 라이브러리를 제공해 줍니다. 여기에 더해 2017년 페이스 북에 의해 오픈 소스화된 파이썬 기반의 Pytorch가 동적 계산 그래프(dynamic computation graph)를 제공하며 순환 신경망(Recurrent Neural Network, RNN) 분야에서 많은 인기를 얻고 있습니다.

DL4J(DeepLearning4J)
자바로 개발된 딥러닝 프레임워크인 DL4J는 자바뿐만 아니라 클로저(Clojure)나 스칼라(Scala)와 같은 다른 JVM 언어도 함께 지원하고 있습니다.
DL4J는 하둡(Hadoop)과 스파크(Spark)를 기반으로 하는 빅데이터 도구와 함께 사용할 수 있으므로 효율적인 딥러닝이 가능하며, Akka와 같은 라이브러리를 사용하여 손쉽게 분산 시스템을 구현할 수 있는 장점을 가집니다.
이러한 DL4J는 비즈니스 환경 중심의 분산 딥러닝 플랫폼으로 널리 사용되고 있습니다.

딥러닝 사례

바이두(Baidu)의 음성 인식
중국의 구글이라 불리는 바이두(Baidu)는 2014년 딥러닝 기술 중 하나인 순환 신경망(RNN)을 이용한 음성인식 프로그램인 딥 스피치(Deep Speech)를 발표하고, 2015년에는 한층 개선된 딥 스피치2를 선보입니다.
딥 스피치는 다른 음성인식 프로그램에 비해 개인의 말투, 사투리, 소음이 심한 환경에서의 음성 인식 정확도를 97%까지 높였습니다.
중국어를 스마트폰에서 입력할 때 딥 스피치를 이용하면 손으로 입력할 때보다 2.8배 빠르고 오타는 60%가량 줄일 수 있다는 통계를 보여줍니다.

페이스북(Facebook)의 얼굴 인식
인공지능의 대가인 얀 레쿤(Yann Lecun) 교수가 이끄는 페이스북 인공지능 팀은 딥러닝 알고리즘을 활용하여 얼굴 인식 알고리즘인 딥페이스(DeepFace)를 개발합니다. 딥페이스는 두 사진에 찍힌 인물이 동일인물인지를 판단하는 프로그램으로 그 정확도가 인간의 눈으로 판단하는 정확도(97.53%)와 거의 비슷한 97.25%에 달합니다.
딥페이스는 정확한 얼굴 분석을 위하여 동물의 중추신경계를 모방해 만든 인공신경망을 분석에 활용하고 있으며, 카메라에 비친 얼굴을 바탕으로 해당 얼굴의 입체를 유추하여 만든 가상 얼굴을 회전시켜 얼굴의 각도를 수정합니다. 이렇게 얻은 가상의 얼굴을 다른 사진의 얼굴과 비교 대조하여 결과를 얻게 됩니다.
이렇게 페이스북은 딥러닝이 적용된 딥페이스 알고리즘으로 전 세계 이용자의 얼굴을 인식하여 특정하고 있습니다.

넷플릭스(Netflix)의 영화 추천
미국 내에서 영화나 TV 드라마 DVD를 온라인으로 대여해 주던 넷플릭스(Netflix)는 현재 인터넷을 통한 실시간 영상 서비스(VOD)를 전세계적으로 제공하는 글로벌 회사로 거듭났습니다.
넷플릭스에서는 현대인의 바쁜 생활 패턴 속에서 보고 싶은 영화를 고르는 행위도 하나의 스트레스가 될 수 있다라는 생각으로 이용자 개개인의 취향에 맞는 영화를 자동으로 추천해 주는 시스템을 만들기로 합니다. 이를 위해 넷플릭스는 자체적으로 영화 추천 엔진인 씨네매치(CineMatch)를 개발하지만, 처음에는 그 성능이 매우 좋지 않았습니다.
이에 넷플릭스에서는 딥러닝 기술을 활용하여 추천 엔진의 이용자별 정확도 향상에 꾸준히 힘을 쏟은 결과, 현재는 이용자가 가장 만족할만한 콘텐츠를 추천하여 이용자들의 만족도가 매우 높은 기업이 되었습니다.

구글(Google)의 인공지능 화가
구글은 알파고의 성공에 힘입어 인간 고유 영역으로만 여겨져 오던 문학, 미술, 음악 등의 예술 분야에도 그 도전장을 내밀고 있습니다.
딥드림(DeepDream)으로 명명된 구글의 컴퓨터 비전 알고리즘은 컨볼루션 신경망(CNN)을 활용하여 다양한 이미지를 인식하고 저장한 뒤 해당 이미지의 특징을 뽑아내어 새로운 이미지로 재구성해줍니다. 딥드림은 학습된 이미지들의 특징을 시각화하고 이를 입력된 이미지와 결합함으로써 환각적인 이미지를 만들어주는 것입니다.
정교한 분석이나 계산이 필요한 분야에만 활용될 것으로 예상되던 인공지능이 인간의 창의력을 바탕으로 한 분야까지 점차 그 영역을 넓혀가고 있는 것입니다.

